{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Company Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"exercise_01_train.csv\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of columns: 101  \n",
    "float data type: 94  \n",
    "int data type: 1  \n",
    "object data type: 6  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing / Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of null values for each columns (Top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 'x96' has most missing values 15.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all categorical ('object') columns/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = df.select_dtypes(\"object\")\n",
    "cat_cols = object_columns.columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with object data type: x34, x35, x41, x68, x93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of missing values from only 'object' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(object_columns).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'x41' and 'x45' can be changed float data type remove signs and replace missing values with median (or mean)\n",
    "The missing values from other categorical features can be replaced with the most frequent category within the column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For x41, x45, remove '$' or '%' sign and change the data type as float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x41'] = df['x41'].str.replace('$','').astype(float)\n",
    "df['x45'] = df['x45'].str.replace('%','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = df.select_dtypes(\"object\")\n",
    "cat_cols = object_columns.columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check unique values from category columns and fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(col+\":\", df[col].unique(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x34'] = df['x34'].str.upper()\n",
    "df['x34'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x35']= (\n",
    "            df['x35'].replace(['wed', 'wednesday'], 'Wednesday')\n",
    "                    .replace(['thur', 'thurday'], 'Thursday')\n",
    "                    .replace(['fri', 'friday'], 'Friday')\n",
    "                    .str.capitalize()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x68']= (\n",
    "            df['x68'].replace('July', 'Jul')\n",
    "                    .replace('sept.', 'Sep')\n",
    "                    .replace('Dev', 'Dec')\n",
    "                    .replace('January', 'Jan')           \n",
    "                    .str.capitalize()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x93'] = df['x93'].str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation: replace missing categorical features with the most frequent in category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols: \n",
    "    df[col][pd.isnull(df[col])] = df[col].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate dataset into categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "cat_df = df.loc[:, df.dtypes == np.object]\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot ecoding - categorical features\n",
    "onehot_cat_df = pd.get_dummies(cat_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical features\n",
    "num_df = df.loc[:, df.dtypes == np.float64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation: replace missing numerical features with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation with median for NA values in numerical features\n",
    "num_df = num_df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling: Starndard Scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "scaled_num_df = pd.DataFrame(scalar.fit_transform(num_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all features are normally distributed but thier scales are different (from .describe() and EDA).  \n",
    "Standardized feautures help SVM perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate: combine dataframes into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.concat([onehot_cat_df, scaled_num_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split (from train set csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling - Random Forest & Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (with Hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Random Forest Hyperparameter Tuning\n",
    "\n",
    "param_grid_rf = {\n",
    "                'n_estimators': [200, 250, 300], \n",
    "                'max_depth': [16, 18, 20], \n",
    "                'min_samples_leaf': [8, 10],\n",
    "                'min_samples_split': [2, 4],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf = GridSearchCV(rf_clf, param_grid=param_grid_rf, cv=3, scoring='roc_auc', n_jobs=-1, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf_proba = grid_search_rf.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC: ', roc_auc_score(y_test, grid_search_rf_proba[:,1]))\n",
    "print('Accuracy: ', accuracy_score(y_test, grid_search_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine - SVM (with Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "param_grid_svm = {'C': [1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['rbf']}  \n",
    "svm_clf = svm.SVC(probability=True)  \n",
    "grid_search_svm = GridSearchCV(svm_clf, param_grid_svm, verbose = True, cv=3, scoring='roc_auc', n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid_search_svm.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_probs = grid_search_svm.predict_proba(X_test)\n",
    "print('AUC: ', roc_auc_score(y_test, svm_clf_probs[:,1]))\n",
    "print('Accuracy: ', accuracy_score(y_test, grid_search_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (with Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {'penalty': ['l1', 'l2'], \n",
    "                 'C': [0.01, 0.1, 1.0, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_lr = GridSearchCV(logreg, param_grid=param_grid_lr, cv=3, scoring='roc_auc', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_lr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf_probs = grid_search_lr.predict_proba(X_test)\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, lr_clf_probs[:,1]))\n",
    "print('Accuracy: ', accuracy_score(y_test, grid_search_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators = 400, learning_rate=0.1, max_depth=3)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "pred = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_probs = xgb_clf.predict_proba(X_test)\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, xgb_clf_probs[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import and transform test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = pd.read_csv('exercise_01_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'x41', 'x45': remove sign \n",
    "def transform_new_test(df=new_test):\n",
    "\n",
    "    df['x41'] = df['x41'].str.replace('$','').astype(float)\n",
    "    df['x45'] = df['x45'].str.replace('%','').astype(float)\n",
    "\n",
    "    # 'x34', 'x35', 'x68', 'x93': fix some categorical values\n",
    "    df['x34'] = df['x34'].str.upper()\n",
    "    df['x34'].unique()\n",
    "\n",
    "    df['x35']= (\n",
    "                df['x35'].replace(['wed', 'wednesday'], 'Wednesday')\n",
    "                        .replace(['thur', 'thurday'], 'Thursday')\n",
    "                        .replace(['fri', 'friday'], 'Friday')\n",
    "                        .str.capitalize()\n",
    "                )\n",
    "\n",
    "    df['x68']= (\n",
    "                df['x68'].replace('July', 'Jul')\n",
    "                        .replace('sept.', 'Sep')\n",
    "                        .replace('Dev', 'Dec')\n",
    "                        .replace('January', 'Jan')           \n",
    "                        .str.capitalize()\n",
    "                )\n",
    "\n",
    "    df['x93'] = df['x93'].str.capitalize()\n",
    "\n",
    "    # Imputatiom with most frequent category for NA values in categorical features\n",
    "    object_columns = df.select_dtypes(\"object\")\n",
    "    cat_cols = object_columns.columns\n",
    "\n",
    "    for col in cat_cols: \n",
    "        df[col][pd.isnull(df[col])] = df[col].value_counts().index[0]\n",
    "\n",
    "    # Separate dataset into categorical and numerical columns\n",
    "    cat_df = df.loc[:, df.dtypes == np.object]\n",
    "    onehot_cat_df = pd.get_dummies(cat_df)\n",
    "\n",
    "    num_df = df.loc[:, df.dtypes == np.float64]\n",
    "\n",
    "    # Imputation with median for NA values in numerical features\n",
    "    num_df = num_df.fillna(df.median())\n",
    "\n",
    "    # Standard Scaler (esp. for SVM)\n",
    "    scalar = StandardScaler()\n",
    "    scaled_num_df = pd.DataFrame(scalar.fit_transform(num_df))\n",
    "\n",
    "    # Concat cleaned categorical and numerical data as one dataframe\n",
    "    X_df = pd.concat([onehot_cat_df, scaled_num_df], axis=1)\n",
    "    \n",
    "    return X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_new = transform_new_test(new_test)\n",
    "X_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create two .csv results files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results 1 - SVM\n",
    "results1 = pd.DataFrame(grid_search_svm.predict_proba(X_df_new)[:,1], index=None)\n",
    "results1.to_csv(\"results1.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results 2 - Random Forest\n",
    "results2 = pd.DataFrame(grid_search_rf.predict_proba(X_df_new)[:,1], index=None)\n",
    "results2.to_csv(\"results2.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
